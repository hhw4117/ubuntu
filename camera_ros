import os
os.environ["QT_QPA_PLATFORM"] = "xcb"
import traceback
import rclpy
from rclpy.node import Node
from geometry_msgs.msg import Point
import cv2
import numpy as np
from ultralytics import YOLO
from openni import openni2

# ================= ÏÑ§Ï†ï =================
OPENNI_REDIST = "/home/hawon/Documents/depth_camera/Openni_Lib"
MODEL_PATH    = "/home/hawon/Documents/depth_camera/cup_datav3/runs/detect/train/weights/best.pt"
CAM_DEVICE    = "/dev/video2"

# ‚òÖ Îã§Ïãú Ï†ïÏßÅÌïòÍ≤å 15pxÎ°ú Î≥µÍµ¨! (Í∏∞Í≥ÑÍ∞Ä Ïã§Ï†úÎ°ú ÎßûÏ∂îÎèÑÎ°ù Í∞ïÏ†úÌï®)
CENTER_TOLERANCE = 15 

WIDTH, HEIGHT = 640, 480
IMG_SIZE = 640
CONF_THRES = 0.75
MIN_Z_MM, MAX_Z_MM = 200, 3000
ALPHA = 0.5
CX, CY = 320.0, 240.0
# ========================================

def clamp(v, lo, hi): return lo if v < lo else hi if v > hi else v

def get_precise_center_depth(depth_mm, cx, cy):
    h, w = depth_mm.shape[:2]
    roi_size = 5
    rx1 = clamp(cx - roi_size, 0, w); rx2 = clamp(cx + roi_size, 0, w)
    ry1 = clamp(cy - roi_size, 0, h); ry2 = clamp(cy + roi_size, 0, h)
    roi = depth_mm[ry1:ry2, rx1:rx2].astype(np.int32)
    valid = roi[(roi >= MIN_Z_MM) & (roi <= MAX_Z_MM)]
    if valid.size > 0: return float(np.median(valid))
    return None

class CameraNode(Node):
    def __init__(self):
        super().__init__('camera_node')
        self.publisher_ = self.create_publisher(Point, '/camera/tracking', 10)
        self.get_logger().info("üì∑ ROS 2 Camera Node Started!")
        
        self.init_openni()
        self.model = YOLO(MODEL_PATH)
        self.cap = cv2.VideoCapture(CAM_DEVICE, cv2.CAP_V4L2)
        
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, WIDTH)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, HEIGHT)
        self.cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*"MJPG"))
        
        self.z_ema = None
        self.timer = self.create_timer(0.03, self.run_loop)

    def init_openni(self):
        os.environ["OPENNI2_REDIST"] = OPENNI_REDIST
        os.environ["OPENNI2_DRIVERS_PATH"] = os.path.join(OPENNI_REDIST, "Drivers")
        try:
            openni2.initialize(OPENNI_REDIST)
            self.dev = openni2.Device.open_any()
            try:
                self.dev.set_image_registration_mode(openni2.IMAGE_REGISTRATION_DEPTH_TO_COLOR)
            except Exception:
                pass
            self.depth_stream = self.dev.create_depth_stream()
            self.depth_stream.set_video_mode(
                openni2.VideoMode(
                    pixelFormat=openni2.PIXEL_FORMAT_DEPTH_1_MM,
                    resolutionX=WIDTH,
                    resolutionY=HEIGHT,
                    fps=30
                )
            )
            self.depth_stream.start()
        except Exception as e:
            self.get_logger().error(f"OPENNI init failed: {e}")
            self.get_logger().error(traceback.format_exc())
            raise

    def run_loop(self):
        self.cap.grab()
        ret, frame = self.cap.read()
        if not ret:
            return

        dframe = self.depth_stream.read_frame()
        depth_mm = np.frombuffer(dframe.get_buffer_as_uint16(), dtype=np.uint16).reshape((HEIGHT, WIDTH))
        
        vis = frame.copy()
        SCREEN_CX, SCREEN_CY = WIDTH // 2, HEIGHT // 2
        
        cv2.rectangle(vis, (SCREEN_CX - CENTER_TOLERANCE, SCREEN_CY - CENTER_TOLERANCE),
                           (SCREEN_CX + CENTER_TOLERANCE, SCREEN_CY + CENTER_TOLERANCE), (0, 255, 255), 2)

        results = self.model.predict(frame, imgsz=IMG_SIZE, conf=CONF_THRES, verbose=False)[0]
        
        msg = Point()
        msg.z = -1.0

        if results.boxes:
            target_box = max(results.boxes, key=lambda b: (b.xyxy[0][2]-b.xyxy[0][0]) * (b.xyxy[0][3]-b.xyxy[0][1]))
            x1, y1, x2, y2 = map(int, target_box.xyxy[0])
            
            obj_cx = (x1 + x2) // 2
            err_x = obj_cx - SCREEN_CX
            
            msg.x = float(err_x)
            
            # Îã§Ïãú ÏóÑÍ≤©ÌïòÍ≤å 15px Ï≤¥ÌÅ¨
            is_perfect_center = (abs(err_x) <= CENTER_TOLERANCE)
            
            info_text = f"Err: {err_x}"
            
            if is_perfect_center:
                z_raw = get_precise_center_depth(depth_mm, SCREEN_CX, SCREEN_CY)
                if z_raw:
                    self.z_ema = z_raw if self.z_ema is None else (ALPHA * z_raw + (1.0 - ALPHA) * self.z_ema)
                    msg.z = float(self.z_ema)
                    info_text += " [LOCKED]"
            else:
                self.z_ema = None
            
            color = (0, 255, 0) if is_perfect_center else (0, 0, 255)
            cv2.rectangle(vis, (x1, y1), (x2, y2), color, 2)
            cv2.putText(vis, info_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

        else:
            msg.x = 0.0
            msg.z = -1.0
            cv2.putText(vis, "NO TARGET", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 2)

        self.publisher_.publish(msg)
        cv2.imshow("ROS2 Camera", vis)
        
        if cv2.waitKey(1) == ord('q'):
            self.destroy_node()
            rclpy.shutdown()

    def destroy_node(self):
        try:
            if hasattr(self, "depth_stream"):
                self.depth_stream.stop()
            if hasattr(self, "dev"):
                pass
            if hasattr(self, "cap") and self.cap:
                self.cap.release()
            cv2.destroyAllWindows()
        except:
            pass
        super().destroy_node()

def main(args=None):
    rclpy.init(args=args)
    node = CameraNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
